
@inproceedings{DBLP:journals/corr/LinMBHPRDZ14,
  title={Microsoft {COCO}: Common Objects in Context},
  author={Tsung-Yi Lin and Michael Maire and Serge J. Belongie and James Hays and Pietro Perona and Deva Ramanan and Piotr Doll{\'a}r and C. Lawrence Zitnick},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  year={2014}
}

@article{DBLP:journals/corr/MaoHTCYM15,
  title={Generation and Comprehension of Unambiguous Object Descriptions},
  author={Junhua Mao and Jonathan Huang and Alexander Toshev and Oana Camburu and Alan L. Yuille and Kevin Murphy},
  journal={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2016},
  pages={11-20}
}

@article{Hu2016,
  title={Utilizing Large Scale Vision and Text Datasets for Image Segmentation from Referring Expressions},
  author={Ronghang Hu and Marcus Rohrbach and Subhashini Venugopalan and Trevor Darrell},
  journal={CoRR},
  year={2016},
  volume={abs/1608.08305}
}

@article{DBLP:journals/corr/abs-1709-02755,
  author    = {Tao Lei and
               Yu Zhang and
               Yoav Artzi},
  title     = {Training {RNNs} as Fast as {CNNs}},
  journal   = {CoRR},
  volume    = {abs/1709.02755},
  year      = {2017},
  url       = {http://arxiv.org/abs/1709.02755},
  archivePrefix = {arXiv},
  eprint    = {1709.02755},
  timestamp = {Tue, 20 Feb 2018 07:20:35 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1709-02755},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@InProceedings{DBLP:journals/corr/RonnebergerFB15,
author="Ronneberger, Olaf
and Fischer, Philipp
and Brox, Thomas",
title="U-Net: Convolutional Networks for Biomedical Image Segmentation",
booktitle="Medical Image Computing and Computer-Assisted Intervention -- MICCAI 2015",
year="2015",
pages="234--241",
abstract="There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at                                           http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net                                                          .",
isbn="978-3-319-24574-4"
}

@inproceedings{DBLP:journals/corr/ChenLXJYF17,
  title={Dual Path Networks},
  author={Yunpeng Chen and Jianan Li and Huaxin Xiao and Xiaojie Jin and Shuicheng Yan and Jiashi Feng},
  booktitle={NIPS},
  year={2017}
}

@article{li2017cvpr,
  title={Tracking by Natural Language Specification},
  author={Li, Zhenyang and Tao, Ran and Gavves, Efstratios and Snoek, Cees G. M. and Smeulders, Arnold W. M.},
  journal={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  year={2017}
}

@article{hu2016segmentation,
  title={Segmentation from Natural Language Expressions},
  author={Hu, Ronghang and Rohrbach, Marcus and Darrell, Trevor},
  journal={Proceedings of the European Conference on Computer Vision (ECCV)},
  year={2016}
}

@article{he_mask_2017,
	title = {Mask R-{CNN}},
	url = {http://arxiv.org/abs/1703.06870},
	abstract = {We present a conceptually simple, flexible, and general framework for object instance segmentation. Our approach efficiently detects objects in an image while simultaneously generating a high-quality segmentation mask for each instance. The method, called Mask R-{CNN}, extends Faster R-{CNN} by adding a branch for predicting an object mask in parallel with the existing branch for bounding box recognition. Mask R-{CNN} is simple to train and adds only a small overhead to Faster R-{CNN}, running at 5 fps. Moreover, Mask R-{CNN} is easy to generalize to other tasks, e.g., allowing us to estimate human poses in the same framework. We show top results in all three tracks of the {COCO} suite of challenges, including instance segmentation, bounding-box object detection, and person keypoint detection. Without tricks, Mask R-{CNN} outperforms all existing, single-model entries on every task, including the {COCO} 2016 challenge winners. We hope our simple and effective approach will serve as a solid baseline and help ease future research in instance-level recognition. Code will be made available.},
	journaltitle = {{arXiv}:1703.06870 [cs]},
	author = {He, Kaiming and Gkioxari, Georgia and Dollár, Piotr and Girshick, Ross},
	urldate = {2017-05-30},
	date = {2017-03-20},
	eprinttype = {arxiv},
	eprint = {1703.06870},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv\:1703.06870 PDF:/Users/milo/Library/Application Support/Zotero/Profiles/wxz0ba3a.default/zotero/storage/26B2WN6R/He et al. - 2017 - Mask R-CNN.pdf:application/pdf;arXiv.org Snapshot:/Users/milo/Library/Application Support/Zotero/Profiles/wxz0ba3a.default/zotero/storage/Q8EENDAD/1703.html:text/html}
}
@inproceedings{zhao2017pspnet,
  author = {Hengshuang Zhao and
            Jianping Shi and
            Xiaojuan Qi and
            Xiaogang Wang and
            Jiaya Jia},
  title = {Pyramid Scene Parsing Network},
  booktitle = {Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year = {2017}
}

@article{DBLP:journals/corr/LongSD14,
  title={Fully Convolutional Networks for Semantic Segmentation},
  author={Evan Shelhamer and Jonathan Long and Trevor Darrell},
  journal={2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2015},
  pages={3431-3440}
}

@article{DBLP:journals/corr/ChenPKMY14,
  author    = {Liang{-}Chieh Chen and
               George Papandreou and
               Iasonas Kokkinos and
               Kevin Murphy and
               Alan L. Yuille},
  title     = {Semantic Image Segmentation with Deep Convolutional Nets and Fully
               Connected CRFs},
  journal   = {CoRR},
  volume    = {abs/1412.7062},
  year      = {2014},
  url       = {http://arxiv.org/abs/1412.7062},
  timestamp = {Wed, 07 Jun 2017 14:42:19 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/ChenPKMY14},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}


@article{liu2017segmentation,
  title={Recurrent Multimodal Interaction for Referring Image Segmentation},
  author={Chenxi Liu and Zhe L. Lin and Xiaohui Shen and Jimei Yang and Xin Lu and Alan L. Yuille},
  journal={2017 IEEE International Conference on Computer Vision (ICCV)},
  year={2017},
  pages={1280-1289}
}

@inproceedings{KazemzadehOrdonezMattenBergEMNLP14,
  title     = {ReferIt Game: Referring to Objects in Photographs of Natural Scenes},
  author    = {Sahar Kazemzadeh and Vicente Ordonez and Mark Matten and Tamara L. Berg},
  year      = {2014},
  booktitle = {EMNLP}
}

@inproceedings{DBLP:journals/corr/YuPYBB16,
  title={Modeling Context in Referring Expressions},
  author={Licheng Yu and Patrick Poirson and Shan Yang and Alexander C. Berg and Tamara L. Berg},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  year={2016}
}

@article{krishna_visual_2016,
  title={Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations},
  author={Ranjay Krishna and Congcong Li and Oliver Groth and Justin Johnson and Kenji Hata and Joshua Kravitz and Stephanie Chen and Yannis Kalantidis and David A. Shamma and Michael S. Bernstein and Li Fei-Fei},
  journal={International Journal of Computer Vision},
  year={2016},
  volume={123},
  pages={32-73}
}

@article{zhu_visual7w:_2015,
  title={Visual7W: Grounded Question Answering in Images},
  author={Congcong Li and Oliver Groth and Michael S. Bernstein and Li Fei-Fei and Yin Wai Li and Fei-fei Li},
  journal={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2016},
  pages={4995-5004}
}


@article{goyal_making_2016,
  title={Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering},
  author={Yash Goyal and Tejas Khot and Douglas Summers-Stay and Dhruv Batra and Devi Parikh},
  journal={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2017},
  pages={6325-6334}
}


@article{zhang_yin_2015,
  title={Yin and Yang: Balancing and Answering Binary Visual Questions},
  author={Peng Zhang and Yash Goyal and Douglas Summers-Stay and Dhruv Batra and Devi Parikh},
  journal={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2016},
  pages={5014-5022}
}

@article{agrawal_vqa:_2015,
  title={VQA: Visual Question Answering},
  author={Aishwarya Agrawal and Jiasen Lu and Stanislaw Antol and Margaret Mitchell and C. Lawrence Zitnick and Devi Parikh and Dhruv Batra},
  journal={2015 IEEE International Conference on Computer Vision (ICCV)},
  year={2015},
  pages={2425-2433}
}

@article{teney_graph-structured_2016,
  title={Graph-Structured Representations for Visual Question Answering},
  author={Damien Teney and Lingqiao Liu and Anton van den Hengel},
  journal={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2017},
  pages={3233-3241}
}

@article{wu_visual_2016,
  title={Visual Question Answering: A Survey of Methods and Datasets},
  author={Qi Wu and Damien Teney and Peng Wang and Chunhua Shen and Anthony R. Dick and Anton van den Hengel},
  journal={Computer Vision and Image Understanding},
  year={2017},
  volume={163},
  pages={21-40}
}

@article{johnson_inferring_2017,
  title={Inferring and Executing Programs for Visual Reasoning},
  author={Justin Johnson and Bharath Hariharan and Laurens van der Maaten and Judy Hoffman and Li Fei-Fei and C. Lawrence Zitnick and Ross B. Girshick},
  journal={2017 IEEE International Conference on Computer Vision (ICCV)},
  year={2017},
  pages={3008-3017}
}

@inproceedings{santoro_simple_2017,
  title={A simple neural network module for relational reasoning},
  author={Adam Santoro and David Raposo and David G. T. Barrett and Mateusz Malinowski and Razvan Pascanu and Peter W. Battaglia and Timothy P. Lillicrap},
  booktitle={NIPS},
  year={2017}
}

@article{DBLP:journals/corr/HuangLW16a,
  title={Densely Connected Convolutional Networks},
  author={Gao Huang and Zhuang Liu and Kilian Q. Weinberger},
  journal={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2017},
  pages={2261-2269}
}

@article{DBLP:journals/corr/HeZRS15,
  title={Deep Residual Learning for Image Recognition},
  author={Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
  journal={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2016},
  pages={770-778}
}

@article{hu_natural_2015,
  title={Natural Language Object Retrieval},
  author={Ronghang Hu and Huazhe Xu and Marcus Rohrbach and Jiashi Feng and Kate Saenko and Trevor Darrell},
  journal={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2016},
  pages={4555-4564}
}

@article{guadarrama_understanding_2016,
author = {Sergio Guadarrama and Erik Rodner and Kate Saenko and Trevor Darrell},
title ={Understanding object descriptions in robotics by open-vocabulary object retrieval and detection},
journal = {The International Journal of Robotics Research},
volume = {35},
number = {1-3},
pages = {265-280},
year = {2016},
doi = {10.1177/0278364915602059},

URL = { 
        https://doi.org/10.1177/0278364915602059
    
},
eprint = { 
        https://doi.org/10.1177/0278364915602059
    
}
,
    abstract = { We address the problem of retrieving and detecting objects based on open-vocabulary natural language queries: given a phrase describing a specific object, for example “the corn flakes box”, the task is to find the best match in a set of images containing candidate objects. When naming objects, humans tend to use natural language with rich semantics, including basic-level categories, fine-grained categories, and instance-level concepts such as brand names. Existing approaches to large-scale object recognition fail in this scenario, as they expect queries that map directly to a fixed set of pre-trained visual categories, for example ImageNet synset tags. We address this limitation by introducing a novel object retrieval method. Given a candidate object image, we first map it to a set of words that are likely to describe it, using several learned image-to-text projections. We also propose a method for handling open vocabularies, that is, words not contained in the training data. We then compare the natural language query to the sets of words predicted for each candidate and select the best match. Our method can combine category- and instance-level semantics in a common representation. We present extensive experimental results on several datasets using both instance-level and category-level matching and show that our approach can accurately retrieve objects based on extremely varied open-vocabulary queries. Furthermore, we show how to process queries referring to objects within scenes, using state-of-the-art adapted detectors. The source code of our approach will be publicly available together with pre-trained models at http://openvoc.berkeleyvision.org and could be directly used for robotics applications. }
}


% Image captioning
@article{hendricks_deep_2015,
  title={Deep Compositional Captioning: Describing Novel Object Categories without Paired Training Data},
  author={Lisa Anne Hendricks and Subhashini Venugopalan and Marcus Rohrbach and Raymond J. Mooney and Kate Saenko and Trevor Darrell},
  journal={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2016},
  pages={1-10}
}

@article{gan_semantic_2016,
  title={Semantic Compositional Networks for Visual Captioning},
  author={Zhe Gan and Chuang Gan and Xiaodong He and Yunchen Pu and Kenneth Tran and Jianfeng Gao and Lawrence Carin and Li Deng},
  journal={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2017},
  pages={1141-1150}
}

@article{johnson_densecap:_2016,
  title={DenseCap: Fully Convolutional Localization Networks for Dense Captioning},
  author={Justin Johnson and Andrej Karpathy and Li Fei-Fei and Congcong Li and Yin Wai Li and Fei-fei Li},
  journal={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2016},
  pages={4565-4574}
}

@inproceedings{yang_review_2016,
  title={Review Networks for Caption Generation},
  author={Zhilin Yang and Ye Yuan and Yuexin Wu and William W. Cohen and Ruslan Salakhutdinov},
  booktitle={NIPS},
  year={2016}
}

@inproceedings{rahman_optimizing_2016,
	title = {Optimizing Intersection-Over-Union in Deep Neural Networks for Image Segmentation},
	isbn = {978-3-319-50834-4 978-3-319-50835-1},
	url = {https://link.springer.com/chapter/10.1007/978-3-319-50835-1_22},
	doi = {10.1007/978-3-319-50835-1_22},
	series = {Lecture Notes in Computer Science},
	abstract = {We consider the problem of learning deep neural networks ({DNNs}) for object category segmentation, where the goal is to label each pixel in an image as being part of a given object (foreground) or not (background). Deep neural networks are usually trained with simple loss functions (e.g., softmax loss). These loss functions are appropriate for standard classification problems where the performance is measured by the overall classification accuracy. For object category segmentation, the two classes (foreground and background) are very imbalanced. The intersection-over-union ({IoU}) is usually used to measure the performance of any object category segmentation method. In this paper, we propose an approach for directly optimizing this {IoU} measure in deep neural networks. Our experimental results on two object category segmentation datasets demonstrate that our approach outperforms {DNNs} trained with standard softmax loss.},
	eventtitle = {International Symposium on Visual Computing},
	pages = {234--244},
	booktitle = {Advances in Visual Computing},
	publisher = {Springer, Cham},
	author = {Rahman, Md Atiqur and Wang, Yang},
	urldate = {2017-11-11},
	date = {2016-12-12},
	langid = {english},
	file = {Snapshot:/Users/milo/Library/Application Support/Zotero/Profiles/wxz0ba3a.default/zotero/storage/JQ32RHSE/978-3-319-50835-1_22.html:text/html}
}

@inproceedings{krizhevsky2012imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  booktitle={Advances in neural information processing systems},
  pages={1097--1105},
  year={2012}
}

@article{DBLP:journals/corr/Graves13,
  author    = {Alex Graves},
  title     = {Generating Sequences With Recurrent Neural Networks},
  journal   = {CoRR},
  volume    = {abs/1308.0850},
  year      = {2013},
  url       = {http://arxiv.org/abs/1308.0850},
  timestamp = {Tue, 10 Dec 2013 12:03:02 +0100},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/Graves13},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@article{DBLP:journals/corr/abs-1303-5778,
  author    = {Alex Graves and
               Abdel{-}rahman Mohamed and
               Geoffrey E. Hinton},
  title     = {Speech Recognition with Deep Recurrent Neural Networks},
  journal   = {CoRR},
  volume    = {abs/1303.5778},
  year      = {2013},
  url       = {http://arxiv.org/abs/1303.5778},
  timestamp = {Mon, 08 Apr 2013 13:28:28 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/abs-1303-5778},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@article{doi:10.1093/bioinformatics/btw678,
author = {Hanson, Jack and Yang, Yuedong and Paliwal, Kuldip and Zhou, Yaoqi},
title = {Improving protein disorder prediction by deep bidirectional long short-term memory recurrent neural networks},
journal = {Bioinformatics},
volume = {33},
number = {5},
pages = {685},
year = {2017},
doi = {10.1093/bioinformatics/btw678},
URL = { + http://dx.doi.org/10.1093/bioinformatics/btw678},
eprint = {/oup/backfile/content_public/journal/bioinformatics/33/5/10.1093_bioinformatics_btw678/4/btw678.pdf}
}



@article{DBLP:journals/corr/SeglerKTW17,
  author    = {Marwin H. S. Segler and
               Thierry Kogej and
               Christian Tyrchan and
               Mark P. Waller},
  title     = {Generating Focussed Molecule Libraries for Drug Discovery with Recurrent
               Neural Networks},
  journal   = {CoRR},
  volume    = {abs/1701.01329},
  year      = {2017},
  url       = {http://arxiv.org/abs/1701.01329},
  timestamp = {Wed, 01 Feb 2017 17:47:56 +0100},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/SeglerKTW17},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@article{Hochreiter:1997:LSM:1246443.1246450,
	author = {Hochreiter, Sepp and Schmidhuber, J\"{u}rgen},
	title = {Long Short-Term Memory},
	journal = {Neural Comput.},
	issue_date = {November 15, 1997},
	volume = {9},
	number = {8},
	month = nov,
	year = {1997},
	issn = {0899-7667},
	pages = {1735--1780},
	numpages = {46},
	url = {http://dx.doi.org/10.1162/neco.1997.9.8.1735},
	doi = {10.1162/neco.1997.9.8.1735},
	acmid = {1246450},
	publisher = {MIT Press},
	address = {Cambridge, MA, USA},
} 

@inproceedings{chen2017reading,
  title={Reading {Wikipedia} to Answer Open-Domain Questions},
  author={Chen, Danqi and Fisch, Adam and Weston, Jason and Bordes, Antoine},
  booktitle={Association for Computational Linguistics (ACL)},
  year={2017}
}

@article{DBLP:journals/corr/ChoMGBSB14,
  author    = {Kyunghyun Cho and
               Bart van Merrienboer and
               {\c{C}}aglar G{\"{u}}l{\c{c}}ehre and
               Fethi Bougares and
               Holger Schwenk and
               Yoshua Bengio},
  title     = {Learning Phrase Representations using {RNN} Encoder-Decoder for Statistical
               Machine Translation},
  journal   = {CoRR},
  volume    = {abs/1406.1078},
  year      = {2014},
  url       = {http://arxiv.org/abs/1406.1078},
  archivePrefix = {arXiv},
  eprint    = {1406.1078},
  timestamp = {Wed, 07 Jun 2017 14:43:08 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/ChoMGBSB14},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}